{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.2958 - accuracy: 0.9176 - val_loss: 0.1210 - val_accuracy: 0.9675\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 17s 10ms/step - loss: 0.1209 - accuracy: 0.9655 - val_loss: 0.0866 - val_accuracy: 0.9775\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0876 - accuracy: 0.9749 - val_loss: 0.0709 - val_accuracy: 0.9817\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 19s 11ms/step - loss: 0.0719 - accuracy: 0.9791 - val_loss: 0.0664 - val_accuracy: 0.9812\n",
      "Training time: 74.6676349640 seconds\n",
      "Testing time: 1.4653494358 seconds\n",
      "accuracy: 0.9763000011444092\n",
      "save as C:\\Users\\minku\\AppData\\Local\\Temp\\tmpuj1bzjju.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minku\\AppData\\Local\\Temp\\ipykernel_16076\\27305550.py:44: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import time\n",
    "\n",
    "'''\n",
    "簡單CNN模型\n",
    "'''\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28,28)),\n",
    "    keras.layers.Reshape(target_shape=(28,28,1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=4, validation_split=0.1)\n",
    "\n",
    "fit_time = time.time() - start_time\n",
    "print(f\"Training time: {fit_time:.10f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "_, baseline_model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "fit_time = time.time() - start_time\n",
    "print(f\"Testing time: {fit_time:.10f} seconds\")\n",
    "\n",
    "print('accuracy:', baseline_model_accuracy)\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('save as', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 36s 71ms/step - loss: 0.0838 - accuracy: 0.9764 - val_loss: 0.0939 - val_accuracy: 0.9762\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 28s 66ms/step - loss: 0.0975 - accuracy: 0.9739 - val_loss: 0.0820 - val_accuracy: 0.9787\n",
      "Training time: 64.1299629211 seconds\n",
      "Testing time: 1.4023017883 seconds\n",
      "baseline accuracy: 0.9763000011444092\n",
      "pruning accuracy: 0.9735999703407288\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "使用剪枝技術微調訓練好的模型\n",
    "'''\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50, final_sparsity=0.8, begin_step=0, end_step=end_step)\n",
    "}\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "model_for_pruning.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_split=validation_split, callbacks=callbacks)\n",
    "\n",
    "fit_time = time.time() - start_time\n",
    "print(f\"Training time: {fit_time:.10f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "fit_time = time.time() - start_time\n",
    "print(f\"Testing time: {fit_time:.10f} seconds\")\n",
    "\n",
    "print('baseline accuracy:', baseline_model_accuracy) \n",
    "print('pruning accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Save pruned Keras model to: C:\\Users\\minku\\AppData\\Local\\Temp\\tmp9rif_ehq.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minku\\AppData\\Local\\Temp\\ipykernel_16076\\4091028920.py:16: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\minku\\AppData\\Local\\Temp\\tmpo66tn70_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\minku\\AppData\\Local\\Temp\\tmpo66tn70_\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save pruned TFLite model to: C:\\Users\\minku\\AppData\\Local\\Temp\\tmpvvp782kd.tflite\n",
      "gzip baseline Keras model size: 78283.00 bytes\n",
      "gzip pruned Keras model size: 25872.00 bytes\n",
      "gzip pruned TFlite model size: 25015.00 bytes\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "使用剪枝技術將模型缩小3倍\n",
    "'''\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression = zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Save pruned Keras model to:', pruned_keras_file)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_tflite_model)\n",
    "print('Save pruned TFLite model to:', pruned_tflite_file)\n",
    "\n",
    "print(\"gzip baseline Keras model size: %.2f bytes\" % (get_gzipped_model_size(keras_file))) #原始model\n",
    "print(\"gzip pruned Keras model size: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file))) #model after purning\n",
    "print(\"gzip pruned TFlite model size: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file))) #TFlite type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\minku\\AppData\\Local\\Temp\\tmpep4sfyhl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\minku\\AppData\\Local\\Temp\\tmpep4sfyhl\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized and pruned TFLite model save to: C:\\Users\\minku\\AppData\\Local\\Temp\\tmp939kvh5u.tflite\n",
      "gzip baseline Keras model size: 78283.00 bytes\n",
      "gzipped quantized and pruned TFlite model size: 8224.00 bytes\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "使用剪枝和量化將模型缩小 10 倍\n",
    "'''\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('quantized and pruned TFLite model save to:', quantized_and_pruned_tflite_file)\n",
    "print(\"gzip baseline Keras model size: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"gzipped quantized and pruned TFlite model size: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "\n",
      "Evaluated on 1000 results so far.\n",
      "\n",
      "Evaluated on 2000 results so far.\n",
      "\n",
      "Evaluated on 3000 results so far.\n",
      "\n",
      "Evaluated on 4000 results so far.\n",
      "\n",
      "Evaluated on 5000 results so far.\n",
      "\n",
      "Evaluated on 6000 results so far.\n",
      "\n",
      "Evaluated on 7000 results so far.\n",
      "\n",
      "Evaluated on 8000 results so far.\n",
      "\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "Testing time: 2.6164758205 seconds\n",
      "after pruning model accuracy: 0.9735999703407288\n",
      "after pruning and quantization model accuracy: 0.9735\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.\\n'.format(n=i))\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == test_labels).mean()\n",
    "    return accuracy\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "fit_time = time.time() - start_time\n",
    "print(f\"Testing time: {fit_time:.10f} seconds\")\n",
    "\n",
    "\n",
    "print('after pruning model accuracy:', model_for_pruning_accuracy)\n",
    "print('after pruning and quantization model accuracy:', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
